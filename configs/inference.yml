backend: vllm

model_name_or_path: Qwen/Qwen2.5-0.5B-Instruct

tokenizer_cfg:
  pretrained_model_name_or_path: ${model_name_or_path}
  trust_remote_code: true


engine_cfg:
  hf:
    pretrained_model_name_or_path: ${...model_name_or_path}
    trust_remote_code: ${tokenizer_cfg.trust_remote_code}
    device_map: auto
  vllm: 
    model: ${model_name_or_path}
    trust_remote_code: true
    gpu_memory_utilization: 0.8
    max_logprobs: 20

sampling_params:
  hf:
    max_new_tokens: 5
    temperature: 0.7
    top_p: 0.9
    top_k: 10
    do_sample: true
  vllm: 
    max_tokens: 10
    temperature: 0.7
    logprobs: 2
    top_p: 0.9
    top_k: 10


input_data:
  - data/tests/inference_input_1.jsonl   # - means a list 